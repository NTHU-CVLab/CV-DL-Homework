{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Generative Adverserial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make folder for saving\n",
    "if not os.path.isdir('output'):\n",
    "    os.mkdir('output')\n",
    "if not os.path.isdir('output/val_results'):\n",
    "    os.mkdir('output/val_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training parameters\n",
    "use_gpu = False\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "train_epochs = 50\n",
    "\n",
    "if use_gpu:\n",
    "    assert torch.cuda.is_available(), 'ERROR: You have no GPU (CUDA device), turn `use_cuda` as False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "* Training data pair `(x, y)` through `MNIST` data loader\n",
    "* Fixed noise `z` and label `y` for validation phase, totally 100 samples: 10 samples per number in 0~9.\n",
    "    * `fixed_z`: shape=`(100, 100)` \n",
    "    * `fixed_y`: shape=`(100, 10)` (one-hot encoded)\n",
    "\n",
    "#### one-hot encode\n",
    "\n",
    "Example, if we want to encode number from 0 to 9 (10 numbers)\n",
    "```yaml\n",
    "0 -> (1, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "1 -> (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "2 -> (0, 0, 1, 0, 0, 0, 0, 0, 0, 0)\n",
    "...\n",
    "9 -> (0, 0, 0, 0, 0, 0, 0, 0, 0, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Training data '''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "''' Validation data '''\n",
    "def one_hot_encode(tensor, output):\n",
    "    return output.scatter_(dim=1, index=tensor.long(), value=1)\n",
    "\n",
    "fixed_z = torch.rand(10 * 10, 100)\n",
    "fixed_y = torch.cat((torch.zeros(10, 1).fill_(i) for i in range(10)), dim=0)\n",
    "fixed_y = one_hot_encode(fixed_y, output=torch.zeros(10 * 10, 10))\n",
    "\n",
    "fixed_z_var = Variable(fixed_z, volatile=True)\n",
    "fixed_y_var = Variable(fixed_y, volatile=True)\n",
    "\n",
    "if use_gpu:\n",
    "    fixed_z_var.cuda()\n",
    "    fixed_y_var.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model\n",
    "- Baseline models\n",
    "- Your advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaselineGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1_z = nn.Linear(100, 1024)\n",
    "        self.fc1_z_bn = nn.BatchNorm1d(1024)\n",
    "        self.fc1_y = nn.Linear(10, 1024)\n",
    "        self.fc1_y_bn = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(2048, 784)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        z = F.relu(self.fc1_z_bn(self.fc1_z(z)))\n",
    "        y = F.relu(self.fc1_y_bn(self.fc1_y(y)))\n",
    "\n",
    "        h = torch.cat([z, y], dim=1)\n",
    "        h = F.tanh(self.fc2(h))\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class BaselineDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1_x = nn.Linear(784, 1024)\n",
    "        self.fc1_y = nn.Linear(10, 1024)\n",
    "        self.fc2 = nn.Linear(2048, 1)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = F.leaky_relu(self.fc1_x(x), 0.2)\n",
    "        y = F.leaky_relu(self.fc1_y(y), 0.2)\n",
    "\n",
    "        h = torch.cat([x, y], dim=1)\n",
    "        h = F.sigmoid(self.fc2(h))\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class AdvancedGenerator(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AdvancedGenerator(nn.Module):\n",
    "    pass\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.zero_()\n",
    "    elif classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_result(sample_images, epoch, result_folder):\n",
    "    fig, ax = plt.subplots(10, 10, figsize=(5, 5))\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            k = i * 10 + j\n",
    "            ax[i, j].get_xaxis().set_visible(False)\n",
    "            ax[i, j].get_yaxis().set_visible(False)\n",
    "            ax[i, j].cla()\n",
    "            ax[i, j].imshow(sample_images[k].cpu().data.view(28, 28).numpy(), cmap='gray')\n",
    "    fig.text(0.5, 0.04, 'Epoch {0}'.format(epoch), ha='center')\n",
    "    plt.savefig(os.path.join(result_folder, 'epoch_{0}.png'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the cGAN\n",
    "1. Define and prepare the generator `G` and discriminator `D` models\n",
    "2. Define loss function\n",
    "3. Build optimizers for updating model weights in training\n",
    "\n",
    "### In each training epoch\n",
    "* Visualize the performance (output) of generator with `fixed_z`\n",
    "* Record the losses for later curve plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network\n",
    "G = # what generator...?\n",
    "D = # what discriminator...?\n",
    "if use_gpu:\n",
    "    G.cuda()\n",
    "    D.cuda()\n",
    "print('==> Model ready!')\n",
    "\n",
    "# loss function: Binary Cross Entropy loss\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "# optimizer: Adam\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "print('==> Ready for training!')\n",
    "\n",
    "print('==> Training start!')\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    G.train()\n",
    "\n",
    "    for x, y in data_loader:\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        ''' (Data) prepare ground truth label for Discriminator\n",
    "        '''\n",
    "        real_label = Variable(torch.ones(batch_size, 1))\n",
    "        fake_label = Variable(torch.zeros(batch_size, 1))\n",
    "        if use_gpu:\n",
    "            real_label.cuda(), fake_label.cuda()\n",
    "\n",
    "        ''' (Train) discriminator D\n",
    "        '''\n",
    "        D_optimizer.zero_grad()\n",
    "\n",
    "        '''real case:\n",
    "            (Data) prepare ground truth data pair x, y\n",
    "            `x` in shape (batch_size, 28 * 28)\n",
    "            `y` in shape (batch_size, 10)\n",
    "        '''\n",
    "        x_var = Variable(x.view(-1, 28 * 28))\n",
    "        y_var = Variable(torch.zeros(batch_size, 10).scatter_(1, y.view(batch_size, 1), 1))\n",
    "        if use_gpu:\n",
    "            x_var.cuda(), y_var.cuda()\n",
    "        # what should D do here? and the loss?\n",
    "        # ...\n",
    "\n",
    "        '''fake case:\n",
    "            (Data) prepare fake random data pair z, y\n",
    "            `z` in shape (batch_size, 100)\n",
    "            `y` in shape (batch_size, 10)\n",
    "        '''\n",
    "        z_var = Variable(torch.rand((batch_size, 100)))\n",
    "        y_var = Variable(torch.zeros(batch_size, 10).scatter_(1, (torch.rand(batch_size, 1) * 10).long(), 1))\n",
    "        if use_gpu:\n",
    "            z_var.cuda(), y_var.cuda()\n",
    "\n",
    "        # in fake case, what should G and D do? and the loss?\n",
    "        # ...\n",
    "\n",
    "        # total loss in D-step and loss backward to the weights\n",
    "\n",
    "        D_optimizer.step()\n",
    "\n",
    "\n",
    "        ''' (Train) generator G\n",
    "        '''\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        '''generator case:\n",
    "            (Data) prepare fake random data pair z, y\n",
    "            `z` in shape (batch_size, 100)\n",
    "            `y` in shape (batch_size, 10)\n",
    "        '''\n",
    "        z_var = Variable(torch.rand((batch_size, 100)))\n",
    "        y_var = Variable(torch.zeros(batch_size, 10).scatter_(1, (torch.rand(batch_size, 1) * 10).long(), 1))\n",
    "        if use_gpu:\n",
    "            z_var.cuda(), y_var.cuda()\n",
    "\n",
    "        # in G-step, what should G and D do? and the loss?\n",
    "        # ...\n",
    "\n",
    "        # loss in G-step and loss backward to the weights\n",
    "\n",
    "        G_optimizer.step()\n",
    "\n",
    "    G.eval()\n",
    "    sample_images = # generate some results from generator with fixed input\n",
    "    validate_result(sample_images, epoch + 1, result_folder='output/val_results')\n",
    "\n",
    "    print('[{0}/{1}] loss_d: {2:.3f}, loss_g: {3:.3f}'.format((epoch + 1), train_epochs, loss_d, loss_g))\n",
    "\n",
    "print('==> Training finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the weights from models\n",
    "Make it convinient for testing instead of training the networks again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(, 'output/generator_weight.pth')\n",
    "torch.save(, 'output/discriminator_weight.pth')\n",
    "print('==> Models saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the training loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "Show the results with trained generator model (2 images for each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
